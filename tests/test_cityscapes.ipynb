{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.parser import Parser\n",
    "\n",
    "C = Parser(\"configs/default.yaml\").C\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datas import get_loader\n",
    "\n",
    "train_loader = get_loader(C.data, \"train\", distributed=False)\n",
    "valid_loader = get_loader(C.data, \"val\", distributed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "def plot(img, mask):\n",
    "    img = to_pil(img).convert(\"RGB\")\n",
    "    mask = mask.numpy()[0]\n",
    "    mask[mask == 255] = 0\n",
    "    \n",
    "    fig, ax  = plt.subplots(1, 2)\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].set_title(f\"Mask : {np.unique(mask)}\")\n",
    "    ax[1].imshow(mask)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in train_loader.dataset:\n",
    "    plot(img, mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import deeplabv3, PointHead, PointRend\n",
    "# from torchvision.models.utils import load_state_dict_from_url\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "net = PointRend(\n",
    "  deeplabv3(**C.net.deeplab),\n",
    "  PointHead(**C.net.pointhead)\n",
    ").to(device)\n",
    "# state_dict = load_state_dict_from_url('*.pth', progress=True)\n",
    "net.load_state_dict(torch.load('*.pth'), strict=True) #state_dict)\n",
    "net.eval()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, mask in train_loader.dataset:\n",
    "  with torch.no_grad():\n",
    "    out = net(img)\n",
    "    \n",
    "  # out 中包含了很多数据，怎么处理还不知道\n",
    "  print(out.keys())\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 4))\n",
    "    fig.suptitle(\"Img / Mask / Uncertainty Map\")\n",
    "    # softmax for normalize\n",
    "    pred = out.softmax(1).argmax(1).float()\n",
    "    \n",
    "    \"\"\"\n",
    "    In Paper,\n",
    "    To measure prediction uncertainty\n",
    "    we use the same strategy during training and inference:\n",
    "    the difference between the most confident\n",
    "    and second most confident class probabilities\n",
    "    \"\"\"\n",
    "    v, i = out.softmax(1).sort(1, descending=True)\n",
    "    # uncertainty = (v[:, -1, :, :] - v[:, -2, :, :]) <= 0.5\n",
    "    uncertainty = - (v[:, 0, :, :] - v[:, 1, :, :])\n",
    "    \n",
    "    # ax[0].imshow(input_pil)\n",
    "    ax[1].imshow(pred[0].numpy())\n",
    "    ax[2].imshow(uncertainty[0].numpy(), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "736b0c78cc1d99c0b85acfba6dbcd08b455cdca873c68b5bf58ffe39a0b0544a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
